알고리즘 성능을 계산할 때는 

절대시간과 상대시간이 나오는데 

상대시간에서 연산(if연산으로 가정했음)의 횟수

연산횟수를 계산을 할 때

1. 최선의 경우 (best case)

2. 평균의 경우 (average case)  ---- quick sort만 쓴다.

3. 최악의 경우 (worst case)

    - 이 알고리즘은 최악의 경우에도 big o(n)가 이것임을 보장한다.    

그럼 big o는 무엇인가?

n ---> T(n) = 3n** 2 + 2n - 1  ---> 그림을 결정하는데 차수가 가장 좋은 것이다.

여기서 3도 버리고 n ** 2 을 O(n** 2)이렇게 적는다. 이거를 Big O of 엔 제곱이다 라고 말하거나 order of 엔 제곱 으로 표현하기도 한다.

O(n** 2) 이것만 보고도 성능을 파악할 수 있다.

O(n) ---> upper bound     -----> 최악의 경우에도 이것보다 나빠지지 않는다.

W(n) ---> under bound     -----> 최선의 경우에도 이거보다 나아질 수 없다. (쓰지 않음)

세타(n) ---> 위에 2개를 더한것  -----> 최선의 경우에도 이거보다 나아질 수 없고 최악에도 이것보다 나빠지진 않는다. 제일 좋은 것인데 구하기가 어렵다.

T(n)의 트랜드가 중요하다. 즉 데이터의 갯수가 늘어날때 점점 성능이 좋아지는지 아니면 성능이 나빠지는지가 중요하다

가장 좋은 성능

1. O(1) : 상수시간(constant) 데이터의 갯수가 4개에서 100만개로 늘어나도 연산횟수는 늘어나지 않는다.

ex) array의 indexing arr[3]  # 꼭 1일 필요는 없다.

ex) linked list 의 insert(), delete()

2. O(log n) : 로그시간 데이터 갯수가 늘어나도 연산횟수는 log 그래프로 증가

ex) binary search

ex) BST insert(), search(), delete()

3. O(n) : 선형시간

ex) linear search

ex) array의 insert , delete

ex) linked list의 search()

나는 데이터를 삽입하는 경우보다 서칭만 한다 ---> 배열만 쓴다.

나는 데이터를 찾는 경우는 잘 없지만 삽입 및 딜리트를 한다 --> linked

나는 다 적당히 한다. ---> BST

4. O(n*log n)---> 일반 n그래프에 log n을 꼽해서 조금 더 높아지는 그래프

ex) quick sort

ex) merse sort

ex) hoop sort

comparison sorting은 그 알고리즘 속도가 nlogn보다 더 좋아질 수 없다.

5. O(n ** 2) ---> 미친듯이 가팔라진다.

ex) bubble sort

ex) msert sort

ex) 

5번과 4번을 비교하면 4번이 훨씬 훨씬 좋다....

Time complexity

O(n)을 보장한다 해서 막 썼는데 서버가 터짐

ram에서 cpu로 갈때는 20cycle

하드 디스크 500000cycle이다.

만약에 n이 하드디스크에 있는 것이라고 하면 미친듯이 느린 것이다. 그럼 그것을 제공하는 곳에 전화해서 

하드에서 가져오는지 파악

실제 현업에서 나가서 뻗는다 이러면 벤치마킹을 해보고 판단해야 한다.

if for문을 3개 쓰는 알고리즘이 있으면 쓰면 안된다. 우리가 알고리즘 짜는데 만약에 for문이 3개 나온다하면 그냥 다시 짜면 된다.

double에서는 

mantisadigit - 53 

1111 1111 1111 1111----> 53개까지 했을 때 어디까지 커버가 가능할까?

9,007,199,254,740,991 ---> 총 15자리까지 완벽 커버가능하다.

여기서 제일 마지막 1은 더 이상 커져도 신뢰할 수 없다. 

CPU
CPU의 기본 구성

1. cu ---> control unit(제어유닛)

2. ALU ---> arithmetic Logic Unit(산술 논리 연산 장치) 덧샘과 뺼샘 같은 산술 연산과 and, or 와 같은 논리 연산을 하는 곳

3. AX, BX, IR, PC는 모두 레지스터이다.

연산 순서 : RAM ---> AX,BX ---> ALU -----> AX ------> RAM

cpu에는 가산기 밖에 없으므로 +,-를 하기위해 보수기가 필요하다. 그것을 활용하는 방법은 

앞에서 확인했었다.



곱셈
그렇다면 과연 곱셈과 나눗셈은 어떻게 이루어질까?

4bit 연산에 맞추어 곱셈을 해보자.

10(10) 와 5(10)의 곱셈을 예로 들어서 진행해보자.



먼저 10을 2진법으로 바꾸면 8 + 2 ---> 1010(2)

5를 2진법으로 바꾸면 4 + 1 ----> 0101(2) 이 된다.



    0000 | 0101 --->처음에 주어진 수를 0000으로 리셋시키고 곱하는 수를 오른쪽에 적는다. 

+ 1010            ---> 위의 0101에서 제일 오른쪽의 수가 1이므로 왼쪽에 1010을 더해준다.

    1010 | 0101 ---> 여기까지의 과정을 거친뒤 shift 오른쪽으로 한번 진행  (shift 1)

    0101 | 0010 ----> 오른쪽으로 shift를 거친뒤에는 제일 앞에 0을 적어준다. 

                        ------> 제일 오른쪽의 숫자가 0이므로 바로 shift 2진행

    0010 | 1001 ----> 제일 뒤의 숫자가 1이므로 + 1010을 진행해준다.

+ 1010        

    1100 | 1001  ----> 이후에 shift 1회 진행 shift 3

    0110 | 0100 -----> 제일 마지막 숫자가 0이므로 shift 4 진행

    0011 | 0010 -----> 제일 앞의 00을 빼고 110010(2)이 답이 된다.






# 왜 곱셈은 오른쪽으로 shift하고 나눗셈은 왼쪽으로 shift를 진행할까??

나눗셈
나눗셈은 어떻게 진행될까? 정리해보자.

그럼 이번에는 

11 / 3을 해보려고 한다. 

먼저 11을 2진수로 바꾸면 1011(2)

3을 2진수로 바꾸면 0011(2) 이다.


나눗셈은 정말 이해가 잘 되지 않는데 

왜 그렇게 하는지

선생님 말로는 0011의 00을 빼고 11로 똑같이 나눗셈을 한다고 생각하면 된다고 했다.

?가 들어가는 곳은 위에 자리수가 0 , 0 으로 되는 것을 이야기 했다.

어떻게 이루어 지는 것을 확인하고 이후에 또 해볼 수 있을 것 같다.



실수
1. 고정 소수점
고정소수점(Fixed Point) 방식은 소수점 이상, 소수점 이하를 특정 비트로 딱 나눠서 처리 하는겁니다.
만약 반반씩 하기로 하면 4바이트 32비트로 처리하면 정수부분은 16비트 소수 부분도 16비트로하는거죠.
아니면 1바이트는 정수부분(8bit) 3바이트는 소수부분(24bit) 맨 앞에 부호비트 빼먹었네요.
어찌됬던간데 32비트가 표현할수 있는건 한계가 있으니 거기서 누가 어떻게 논갈라먹느냐입니다.

실제 함수를 작성하면서 정수부분은 거의 범위가 적고 소수자리는 길게 필요하다면
소수부분에 비트를 많이 할당할 수 있는거죠.

?? ---> 선생님은 정밀도는 높았으나 표현 범위가 낮았다는 말씀을 하셨다.

2. 부동소수점(Float Point)
--->정밀도는 낮으나 표현범위 갑/ 따라서 어떻게 정밀도를 핸들링 할 것인가가 관건
위에 고정소수점은 소수점 위치를 정하고 그이상 그 이하 나눠서 처리 했으니
이번엔 소수점 위치가 계속 바뀌는건가 라고 생각하시겠지만 아닙니다.

컴퓨터 언어에서 쓰이는 실수형 자료형(float이나 double)은 보통 부동소수점 방식을 씁니다.
근데 이 규격은 IEEE에서 정합니다. (여기서 쓰이는건 IEEE 754 입니다.)

IEEE 754는 아래 그림과 같은 방식으로 표현됩니다.

1023 ----> 102.3 x 10 / 10.23 x 10 **2 / 1.023 x 10 **3 / 0.1023 x 10 **4 와 같이 다양한 형태로 나타낼 수 있다. 여기서 floating point가 나오는데

floating 은 둥둥 떠다닌다를 뜻한다 이 말은 소수점의 위치가 언제든지 옴겨질 수 있는 것을 말한다.


그럼 본격적으로 부동소수점에 대해 알아보자.

부동소수점은 단정도 부동소수점과 배정도 부동소수점으로 나누어 진다.

1. 단정도 (single precision)
    1) 32 bit  (4byte)

    2) 부호(1bit) + 지수(8bit) + 가수(23bit)  #지수부를 넓힌다는 건 표현범위를 넓힌다는 것이다. #가수부를 넓힌다는 건 정밀도를 넓힌다는 것이다.



2. 배정도(double precision)
    1) 64 bit (8byte)

    2) 부호(1bit) + 지수(11bit) + 가수(52bit)   #단정도에 비해 정밀도가 거이 2배이고 표현범위도 늘어남  #단 메모리를 많이 쓰게 됨. 따라서 double을 되도록 안쓰고 싶어한다??



#파이썬은 기본적으로 배정도를 사용한다.

import sys

sys.float_info를 해보면


가수부를 뜻하는 mant_dig을 볼 수 있는데 여기서 53이 되어있는 것을 볼 수 있다. 이는 파이썬이 배정도를 사용한다는 것을 알 수 있음과 동시에 배정도는 가수부가 52bit인데 왜 53bit가 할당되어 있는지에 대한 의문저 역시 품게 된다.



이를 해결하기 위해서는 정규화에 대해 알아야 한다.



정규화에 대해서 알아야 한다.

5234 -> 523.4 x 10*1

     -> 52.34 x 10** 2

     -> 5.234 x 10 ** 3  

 이중에서 무엇을 메모리에 저장할 것인가? 

 이 수를 정규화시키고 저장하자

정규화란? 정수 부분이 0이 아닌 1자리 자연수로 만드는 것이다.

110.1(2) ---> 1.101 x 2** 2 

0.0000111 ---> 1.11 x 2 ** -5 ---> 여기서 1.11을 가수부 2**5는 지수부 2는 기수라고 한다.

따라서 2진수에는 제일 앞이 무조건 0이 아니라 1이 되게 된다.( 1자리 자연수)

+- 1.man x 2 ** ---> 여기서 1. 은 멘티사(가수)이지만 따로 저장하지 않는다.

따라서 1.은 따로 저장하지 않으면 더 좋다.

1.010101 x 2** 4 일 때 저장은 010101(가수) 이후에 000000000000 으로 나머지 가수부분을 채운다.

따라서 파이썬에서는 man_dig ---> 1. 을 포함하므로 53개로 나타남(왜냐하면 1도 실제로 가수부이므로)

---> 이런 일로 인해서 실제 메모리에 저장되는 것과 파이썬에 나타나는 것과 차이가 나타나게 된다.



다음으로 넘어가서 2**5 에서 전체는 지수부라고 표현하고 2는 기수 5는 exponent(제곱) real 이라고 부른다. 여기서 exponent real은 exp - bias로 구할 수 있다.


여기서 bias는 상수인데 bias를 알면 exponent를 구할 수 있다.


따라서 float에서는 지수가 항상 8자리의 비트를 가지므로 bias는 127이다.

Ere = Emem - bias

Emem = Ere + bias  ----> 5 + 127 = 132 를 2진수로 바꾼게 Emem 가 된다.



이제 예를 들어 실행해보자

만약에 특정 변수에 10.625라고 변수를 할당해주면 과연 10.625는 어떻게 메모리에 저장될까?



먼저 10.625로 2진수로 바꾸어야 한다. 

10.625 = 8 + 2 + 0.5+ 0.125 (현실에서는 이것보다 복잡하는 2진수로 바꾸는게 쉽지 않다)

= 1010.101(2)



이 숫자는 1.010101(2) x 2 ** 3으로 나타난다.

앞에 가수부의 1.을 제외한 010101이 가수부에 저장되고 (가수부는 52자리를 지원하므로 나머지 부분은 모두 0으로 저장) 

Ere = Emem - bias 이므로 Emem = Ere + bias 이다.

따라서 지수부를 나타내는 Emem = 3 + 127 이므로 130 이다.

130을 2진법 수로 나타내면 128 + 2 ----> 2 ** 7 + 2 ----> 10000010 이 된다.

따라서 명확하게 적어보면

0(sign) 10000010 (지수부) 01010100000000000----(가수부 52자리)로 적을 수 있다.



그렇다면 0.01을 100번 더했을 때 1이 나오지 않는 이유는 무엇일까?

이는 0.01을 2진법 수로 바꾸었을 때 가수부를 나타내는 자리수가 부족했음을 알 수 있다. 그 숫자의 차이는 미비하나 100번이나 더 해주었을 때 어느정도의 차이를 만들어낸다.

#몇자리가 부족한거야? 23자리? 52자리?? 이야기는 23자리로 해주셨는데 파이썬은 52자리를 쓰는데??



따라서 정밀도에 대한 문제를 부동소수점에서는 꼭 다루어야 하는데 그것의 시작이 바로 옙실론이다.



엡실론(epsilon)
먼저 엡실론을 파이썬에서

sys.float_info.epsilon이라고 서칭해보면

2.220446049250313e-16와 같은 값이 나온다. 굉장히 작은 숫자이다.



엡실론의 정의는 epsilon difference between 1 and the next representable float

==> 1과 그 다음에 나올 수 있는 값의 차이를 이야기 한다.



sys.float_info.dig ----> 15 (digit 는 자리수)

그럼 여기서 말하는 15자리는 무엇인가?

먼저, 정밀도는 소수점 아래 6자리 실수 정밀도라고 적힌 책은 버려야 한다.(by teacher)



2진수 몇자리수로 10진수 1자리를 표현할 수 있을까?

10진수 1의 자리는 9까지 표현할 수 있으면 되는데 9는 ----> 1001(2) 이므로 4자리가 있으면 다 표현할 수 있다.  

2진수 1111 채우면 10진수로 15까지 표현 가능  ----> 9보다 15가 크므로 1자리수는 완전히 커버 가능함

1111 111 7자리를 채우면 10진수 127까지 표현 가능 ----> 2자리수는 완벽히 커버가능

1111 1111 11 10자리를 채우면 10진수 1023까지 표현 가능 ----> 3자리 완벽히 커버가능

floating에서 가수부는 총 23bit에 기본 1.0 1bit를 더해 총 24bit 까지 커버가능한데.

과연 1111 1111 1111 1111 ----- 24까지 했을 때 어디까지 커버가 가능할까?

10진수로 나타내면 16,777,215 이다. 즉 완벽히 커버 가능한 자리는 9.999.999 총 7자리에 대해 커버가 가능한다. 이는 6 ~ 7 자리를 이야기 할 수 있고 10진수로 7자리를 표현할 수 있다는 정밀도가 있는 것이다.



double에서는 mantisadigit - 53 

1111 1111 1111 1111----> 53개까지 했을 때 어디까지 커버가 가능할까?

9,007,199,254,740,991 ---> 총 15자리까지 완벽 커버가능하다.

여기서 제일 마지막 1은 더 이상 커져도 신뢰할 수 없다. 


실수 1.0 다음 수에 대해 생각해 보자.

1.0 x 2 ** 0 그 다음은 1.00000000000000000000001(23자리 뒤의 1) x 2 ** 0 이고

따라서 차이는 1.0 x 2 ** -23로 나타낼 수 있다.



double은 1.0x 2 ** -52

sys.float_info.epsilon == 2.0**-52 해보면 True가 나오게 된다.

double로 변하면서 정밀도가 훨씬 좋아져 epsilon의 값도 많이 작아지게 된다.


epsilon 컴페어리즘
그럼 이 엡실론을 어디에 쓰일 수 있을까??



float a = 10.5 다음에 쓰일 수 있는 수 사이의 차이를 구해보자.

10.5 = 8 + 2 + 0.5 = 2 ** 3 + 2 ** 1 + 2 * -1 = 1.0101(2) x 2 ** 3

diff = 2 ** e x epsilon( 2 ** -23)

2 ** 3 x 2 ** -23 = 2** -20의 간격을 두고 다음 수가 쓰일 수 있다.

 하지만 이렇게 하면 너무 시간이 오래 걸린다.


매번 2진수로 바꾸고 지수부를 구하기에는 시간이 너무 오래 걸리므로 지수부보다 num은 무조건 크므로 지수부 대신 num을 쓰게 되면 사이 간격을 나타내는데 더 보수적으로 쓰게 되는 것이다. 

하지만 여기서는 더 보수적으로 잡아서 표현범위를 나타내는 지수부를 그대로 num으로 근사시켜 사용한다. 

이렇게 되게 되면 우리는 너무나도 쉽게 다음에 쓰일 수와의 차이를 알 수 있다.



실수 비교
1. 따라서 실수는 if(a==b)처럼 직접 비교하면 안된다. 

그러므로 a,b를 비교하는 함수를 작성해 비교한다. # 오히려 배우고 나니 문제가 더 커진 기분이다.

def is.equal(a,b):

    return True of False



여기서 실수 비교 기법 2가지가 나온다.

1. 절대 비교 기법
def is_equal(a,b):

    return |a-b| <= 1e-10    

두 수의 차이가 1e - 10 보다 작다면 같다고 생각해도 무방하다.

하지만 1e - 10을 어떻게 정할 것인가? 함수를 만들어 놓은 이유는 계속해서 쓰기 위해서 인데

이렇게 해놓으면 매번 함수의 구현을 바꾸어야 하므로 매번 내부함수를 바꿔야 하므로 추상화에 위반된다.

from math import fabs

def is_equal(a,b):

    return fabs(a-b)<= 1.0e-10    #fabs는 절대값을 나타내는 math모듈에 있는 함수??이다.



if is_equal(a,b):

    print("이 정도 차이면 봐줄게")

else:

    print("이건 같은 수가 아니징")



따라서 우리는 매번 1e - 10을 필요에 따라 바꾸어야 하는 문제가 발생한다.

1e - 10을 수학적으로 족보를 가진 애로 만들어야 겠다.



2. 상대 비교 기법 ##
relative Error = fabs(a-b)/max(fabs(a). fabs(b)) #max는 둘중에 큰수
분수로 표시하는 이유는 5.5와 5.3의 차이 그리고 55와 53의 차이를 똑같게 만들어 준다.



from math import fabs

import sys

def is_equal(a, b, w=0):

    """

    is_equal(a, b, w = 0) ---> bool

    w는 가중치입니다. w를 조정함으로서 diff의 범위를 조정할 수 있다.

    w를 0부터 늘려가며 상대 오차 범위를 조정해주세요    

    """

    ep = sys.float_info.epsilon

    diff=fabs(a-b)    

    return diff <= max(fabs(a), fabs(b))*ep*(2**w) #큰 값을 하는 이유는 큰수를 해서 조금 더 오차를 인정해주자 그런 느낌으로 보면 된다.



위와 같은 것을 epsilon 컴페어리즘이라고 한다. 

즉 오차범위를 어디까지 허용할지 내가 직접 함수를 만들어서 가중치를 조절해가며 쓸 수 있는 것이다.

원래 

a = 3.0

b = 1.0 * 3

a == b 하면 false가 나오나

위의 값에 비교해보면

if is_equal(a,b):

        print('things')

things가 적히게 된다.



#번회 알고리즘 성능
알고리즘 성능 (어제꺼에서 추가)¶
알고리즘 성능을 계산할 때는 

절대시간과 상대시간이 나오는데 

상대시간에서 연산(if연산으로 가정했음)의 횟수

연산횟수를 계산을 할 때

1. 최선의 경우 (best case)

2. 평균의 경우 (average case)  ---- quick sort만 쓴다.

3. 최악의 경우 (worst case)

    - 이 알고리즘은 최악의 경우에도 big o(n)가 이것임을 보장한다.    

그럼 big o는 무엇인가?

n ---> T(n) = 3n** 2 + 2n - 1  ---> 그림을 결정하는데 차수가 가장 좋은 것이다.

여기서 3도 버리고 n ** 2 을 O(n** 2)이렇게 적는다. 이거를 Big O of 엔 제곱이다 라고 말하거나 order of 엔 제곱 으로 표현하기도 한다.

O(n** 2) 이것만 보고도 성능을 파악할 수 있다.

O(n) ---> upper bound     -----> 최악의 경우에도 이것보다 나빠지지 않는다.

W(n) ---> under bound     -----> 최선의 경우에도 이거보다 나아질 수 없다. (쓰지 않음)

세타(n) ---> 위에 2개를 더한것  -----> 최선의 경우에도 이거보다 나아질 수 없고 최악에도 이것보다 나빠지진 않는다. 제일 좋은 것인데 구하기가 어렵다.

T(n)의 트랜드가 중요하다. 즉 데이터의 갯수가 늘어날때 점점 성능이 좋아지는지 아니면 성능이 나빠지는지가 중요하다

가장 좋은 성능

1. O(1) : 상수시간(constant) 데이터의 갯수가 4개에서 100만개로 늘어나도 연산횟수는 늘어나지 않는다.
ex) array의 indexing arr[3]  # 꼭 1일 필요는 없다.

ex) linked list 의 insert(), delete()

2. O(log n) : 로그시간 데이터 갯수가 늘어나도 연산횟수는 log 그래프로 증가
ex) binary search

ex) BST insert(), search(), delete()

3. O(n) : 선형시간
ex) linear search

ex) array의 insert , delete

ex) linked list의 search()

나는 데이터를 삽입하는 경우보다 서칭만 한다 ---> 배열만 쓴다.

나는 데이터를 찾는 경우는 잘 없지만 삽입 및 딜리트를 한다 --> linked

나는 다 적당히 한다. ---> BST

4. O(n*log n)---> 일반 n그래프에 log n을 꼽해서 조금 더 높아지는 그래프
ex) quick sort

ex) merse sort

ex) hoop sort

comparison sorting은 그 알고리즘 속도가 nlogn보다 더 좋아질 수 없다.

5. O(n ** 2) ---> 미친듯이 가팔라진다.
ex) bubble sort

ex) msert sort

ex) 

5번과 4번을 비교하면 4번이 훨씬 훨씬 좋다....

Time complexity

O(n)을 보장한다 해서 막 썼는데 서버가 터짐

ram에서 cpu로 갈때는 20cycle

하드 디스크 500000cycle이다.

만약에 n이 하드디스크에 있는 것이라고 하면 미친듯이 느린 것이다. 그럼 그것을 제공하는 곳에 전화해서 

하드에서 가져오는지 파악

실제 현업에서 나가서 뻗는다 이러면 벤치마킹을 해보고 판단해야 한다.

if for문을 3개 쓰는 알고리즘이 있으면 쓰면 안된다. 우리가 알고리즘 짜는데 만약에 for문이 3개 나온다하면 그냥 다시 짜면 된다.
